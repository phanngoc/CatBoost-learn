# Táº¡i sao **CatBoost** (má»™t thuáº­t toÃ¡n gradient boosting do Yandex phÃ¡t triá»ƒn) láº¡i thÆ°á»ng cÃ³ hiá»‡u suáº¥t cao hÆ¡n cÃ¡c thuáº­t toÃ¡n boosting khÃ¡c nhÆ° XGBoost, LightGBM. Äá»ƒ báº¡n dá»… hÃ¬nh dung mÃ¬nh sáº½ **giáº£i thÃ­ch tá»«ng Ä‘iá»ƒm má»™t cÃ¡ch diá»…n giáº£i vÃ  tÃ­nh toÃ¡n minh há»a cá»¥ thá»ƒ**, chá»© khÃ´ng chá»‰ nÃ³i lÃ½ thuyáº¿t suÃ´ng.

---

### 1ï¸âƒ£ **Ordered Boosting** (TÄƒng cÆ°á»ng cÃ³ tráº­t tá»±)

> Giáº£i quyáº¿t váº¥n Ä‘á» **target leakage** (rÃ² rá»‰ nhÃ£n) khi huáº¥n luyá»‡n.

ğŸ“Œ **Váº¥n Ä‘á» cá»§a boosting truyá»n thá»‘ng (XGBoost/LightGBM)**
á» cÃ¡c thuáº­t toÃ¡n boosting bÃ¬nh thÆ°á»ng, khi báº¡n huáº¥n luyá»‡n cÃ¢y thá»© k+1, mÃ´ hÃ¬nh dÃ¹ng toÃ n bá»™ dá»¯ liá»‡u Ä‘Ã£ biáº¿t (gá»“m cáº£ nhÃ£n y) Ä‘á»ƒ tÃ­nh toÃ¡n residuals (sai sá»‘). Äiá»u nÃ y gÃ¢y rÃ² rá»‰ thÃ´ng tin vÃ¬ báº¡n Ä‘ang â€œnhÃ¬n trá»™mâ€ nhÃ£n tháº­t Ä‘á»ƒ xÃ¢y cÃ¢y tiáº¿p theo, dá»… **overfit**.

ğŸ“Œ **CÃ¡ch CatBoost giáº£i quyáº¿t**
CatBoost chia nhá» dá»¯ liá»‡u thÃ nh cÃ¡c **tiá»ƒu bá»™ (permutation)**, vÃ  má»—i láº§n tÃ­nh residual cho 1 máº«u, nÃ³ chá»‰ dÃ¹ng nhá»¯ng máº«u **trÆ°á»›c Ä‘Ã³** (khÃ´ng dÃ¹ng nhÃ£n cá»§a chÃ­nh nÃ³). Äiá»u nÃ y giá»‘ng nhÆ° **out-of-fold prediction**.

ğŸ§® **VÃ­ dá»¥**
Giáº£ sá»­ báº¡n cÃ³ 4 sample:

| Index | Feature X | Target y |
| ----- | --------- | -------- |
| 1     | A         | 10       |
| 2     | B         | 15       |
| 3     | A         | 20       |
| 4     | B         | 25       |

* Náº¿u theo CatBoost, khi tÃ­nh residual cho sample 3, chá»‰ dÃ¹ng sample 1 vÃ  2 (khÃ´ng dÃ¹ng nhÃ£n cá»§a sample 3).
* Äiá»u nÃ y lÃ m sai sá»‘ Ä‘Æ°á»£c Æ°á»›c lÆ°á»£ng **trung thá»±c hÆ¡n**, giáº£m overfitting.

ğŸŸ¢ **Káº¿t quáº£**: TÄƒng kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a (**generalization**) vÃ¬ khÃ´ng â€œnhÃ¬n trá»™mâ€ nhÃ£n.

---

### 2ï¸âƒ£ **Special Handling of Categorical Features** (Xá»­ lÃ½ Ä‘áº·c biá»‡t cho biáº¿n phÃ¢n loáº¡i)

ğŸ“Œ **Váº¥n Ä‘á» cá»§a one-hot encoding (OHE)**
CÃ¡c thuáº­t toÃ¡n nhÆ° XGBoost thÆ°á»ng dÃ¹ng **OHE** hoáº·c **Label Encoding**, nhÆ°ng náº¿u **cardinality** (sá»‘ lÆ°á»£ng giÃ¡ trá»‹ khÃ¡c nhau) cao thÃ¬:

* One-hot => táº¡o ma tráº­n ráº¥t thÆ°a (sparse), ráº¥t tá»‘n RAM.
* Label encoding => Ä‘Æ°a thá»© tá»± giáº£ táº¡o vÃ o, gÃ¢y sai lá»‡ch.

ğŸ“Œ **CÃ¡ch CatBoost lÃ m**
CatBoost dÃ¹ng ká»¹ thuáº­t **Target Statistics (TS)**:

* Vá»›i má»—i giÃ¡ trá»‹ cá»§a biáº¿n phÃ¢n loáº¡i, CatBoost tÃ­nh **mean(target)** trÃªn cÃ¡c máº«u trÆ°á»›c Ä‘Ã³.

ğŸ§® **VÃ­ dá»¥**
Vá»›i biáº¿n **Feature X** cÃ³ giÃ¡ trá»‹ `A` vÃ  `B` nhÆ° trÃªn:

* Vá»›i A (cÃ¡c index 1, 3):

  * Khi xÃ©t sample 1 â†’ chÆ°a cÃ³ sample trÆ°á»›c â†’ dÃ¹ng prior (giáº£ sá»­ = 17.5)
  * Khi xÃ©t sample 3 â†’ sample trÆ°á»›c lÃ  (1): mean = yâ‚ = 10

* Vá»›i B (index 2, 4):

  * Sample 2 â†’ chÆ°a cÃ³ sample trÆ°á»›c â†’ prior = 17.5
  * Sample 4 â†’ sample trÆ°á»›c lÃ  (2): mean = yâ‚‚ = 15

| Index | Feature X | Target Mean (TS encoding) |
| ----- | --------- | ------------------------- |
| 1     | A         | 17.5 (prior)              |
| 2     | B         | 17.5 (prior)              |
| 3     | A         | 10                        |
| 4     | B         | 15                        |

ğŸŸ¢ **Káº¿t quáº£**:

* KhÃ´ng táº¡o ma tráº­n thÆ°a (Ã­t RAM)
* Encoding pháº£n Ã¡nh **má»‘i quan há»‡ tháº­t sá»± vá»›i y**, giÃºp mÃ´ hÃ¬nh há»c tá»‘t hÆ¡n.

---

### 3ï¸âƒ£ **Model Shrinkage** (Thu háº¹p mÃ´ hÃ¬nh)

> Má»™t cÃ¡ch "kiá»m cháº¿" mÃ´ hÃ¬nh khÃ´ng há»c quÃ¡ má»©c.

ğŸ“Œ **Trong boosting truyá»n thá»‘ng**

* Shrinkage = **Learning rate** (giáº£m tá»‘c Ä‘á»™ cáº­p nháº­t)
* NhÆ°ng CatBoost thÃªm **Leaf-wise shrinkage** sau khi cÃ¢y Ä‘Æ°á»£c xÃ¢y xong.

ğŸ§® **VÃ­ dá»¥**
Giáº£ sá»­ báº¡n cÃ³ 1 cÃ¢y vá»›i **leaf values** (giÃ¡ trá»‹ á»Ÿ lÃ¡):

| Leaf | Value (before shrinkage) |
| ---- | ------------------------ |
| 1    | +5                       |
| 2    | â€“3                       |
| 3    | +2                       |
| 4    | â€“6                       |

* Náº¿u shrinkage = 0.8
  â†’ Value má»›i = Value Ã— 0.8

| Leaf | Value (after shrinkage) |
| ---- | ----------------------- |
| 1    | +4.0                    |
| 2    | â€“2.4                    |
| 3    | +1.6                    |
| 4    | â€“4.8                    |

ğŸŸ¢ **Káº¿t quáº£**:

* Giáº£m biáº¿n Ä‘á»™ng cá»±c Ä‘oan á»Ÿ lÃ¡ â†’ giáº£m overfit
* Tá»•ng thá»ƒ mÃ´ hÃ¬nh â€œdá»‹u hÆ¡nâ€, dá»… tá»•ng quÃ¡t hÃ³a hÆ¡n

---

## ğŸ¯ **TÃ³m láº¡i â€” Táº¡i sao CatBoost tá»•ng quÃ¡t hÃ³a tá»‘t hÆ¡n?**

| Ká»¹ thuáº­t                   | Giáº£i thÃ­ch                                             | Hiá»‡u á»©ng                        |
| -------------------------- | ------------------------------------------------------ | ------------------------------- |
| Ordered Boosting           | KhÃ´ng nhÃ¬n trá»™m nhÃ£n khi huáº¥n luyá»‡n                    | Giáº£m overfit                    |
| Target Statistics Encoding | Biáº¿n phÃ¢n loáº¡i Ä‘Æ°á»£c mÃ£ hÃ³a tinh táº¿, trÃ¡nh giáº£ Ä‘á»‹nh sai | Há»c tá»‘t hÆ¡n trÃªn biáº¿n phÃ¢n loáº¡i |
| Leaf-wise Shrinkage        | Kiá»m cháº¿ giÃ¡ trá»‹ á»Ÿ lÃ¡ cÃ¢y                              | MÃ´ hÃ¬nh Ã­t cá»±c Ä‘oan hÆ¡n         |

---

Náº¿u báº¡n muá»‘n, tÃ´i cÃ³ thá»ƒ lÃ m thÃªm **so sÃ¡nh báº±ng code Python (CatBoost vs XGBoost)** vá»›i dataset máº«u Ä‘á»ƒ báº¡n tháº¥y sá»± khÃ¡c biá»‡t vá» **accuracy** vÃ  **overfitting**. Báº¡n cÃ³ muá»‘n khÃ´ng? ğŸ“Š
